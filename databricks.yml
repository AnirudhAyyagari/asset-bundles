bundle:
  name: banking_default_model_bundle

workspace:
  host: https://dbc-64239bfe-e47d.cloud.databricks.com
  file_path: /Workspace/Users/${workspace.current_user.userName}/.bundle/${bundle.name}/${bundle.target}/files

# Sync notebooks to workspace
sync:
  include:
    - "*.yml"
    - "notebooks/*.ipynb"
    - "notebooks/*.py"

targets:
  default:
    mode: development
    workspace:
      root_path: /Workspace/Users/${workspace.current_user.userName}/.bundle/${bundle.name}/${bundle.target}

resources:
  jobs:
    # -------------------------------------------------------
    # 1. Model Registration Job
    # -------------------------------------------------------
    Banking_Model_Register:
      name: Banking_Model_Register
      tasks:
        - task_key: register_model
          description: "Registers the latest MLflow run into the model registry"
          notebook_task:
            notebook_path: ${workspace.file_path}/notebooks/ModelRegistry
            source: WORKSPACE
          timeout_seconds: 1800
          # ADD: Cluster configuration (choose one option below)
          
          # Option 1: Use an existing cluster (RECOMMENDED for testing)
          existing_cluster_id: "1106-004407-u87y9m7a-v2n"
          
          # Option 2: Create a new cluster for each run
          # new_cluster:
          #   spark_version: "13.3.x-scala2.12"
          #   node_type_id: "i3.xlarge"
          #   num_workers: 2
          #   spark_conf:
          #     "spark.databricks.delta.preview.enabled": "true"

    # -------------------------------------------------------
    # 2. Batch Inference Job (uses champion model)
    # -------------------------------------------------------
    Banking_Default_Inference:
      name: Banking_Default_Inference
      tasks:
        - task_key: inference
          description: "Runs batch inference using the champion model"
          notebook_task:
            notebook_path: ${workspace.file_path}/notebooks/Deploy
            source: WORKSPACE
          timeout_seconds: 3600
          # ADD: Cluster configuration
          existing_cluster_id: "1106-004407-u87y9m7a-v2n"
          
          # Or use new_cluster option like above
      schedule:
        quartz_cron_expression: "0 0 9 * * ?" 
        timezone_id: Pacific/Auckland