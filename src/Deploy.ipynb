{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "51342591-1398-4c52-98b3-b5f8939775b0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Databricks notebook: Step 5 – Batch Inference (Fixed)\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "import os\n",
    "import mlflow\n",
    "import numpy as np\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 1. Environment setup\n",
    "# --------------------------------------------------\n",
    "os.environ[\"MLFLOW_DFS_TMP\"] = \"/Volumes/banking/default/mlflow_tmp\"\n",
    "mlflow.set_registry_uri(\"databricks-uc\")\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 2. Load raw inference data\n",
    "# --------------------------------------------------\n",
    "raw_df = spark.read.table(\"default.raw_credit_data\").sample(fraction=0.1, seed=42)\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 3. Apply same feature engineering as training\n",
    "# --------------------------------------------------\n",
    "df = (\n",
    "    raw_df.fillna({\n",
    "        \"gender\": \"Unknown\",\n",
    "        \"marital_status\": \"Unknown\",\n",
    "        \"employment_type\": \"Unknown\",\n",
    "        \"occupation_risk\": \"Unknown\",\n",
    "        \"purpose\": \"Unknown\",\n",
    "        \"region_risk_tier\": \"Unknown\"\n",
    "    })\n",
    "    .withColumn(\"debt_to_income\", F.when(F.col(\"debt_to_income\") > 1, 1).otherwise(F.col(\"debt_to_income\")))\n",
    "    .withColumn(\"payment_to_income\", F.when(F.col(\"payment_to_income\") > 1, 1).otherwise(F.col(\"payment_to_income\")))\n",
    "    .withColumn(\"credit_limit_utilization\", F.when(F.col(\"credit_limit_utilization\") > 1, 1).otherwise(F.col(\"credit_limit_utilization\")))\n",
    "    .withColumn(\"loan_to_income\", F.col(\"loan_amount\") / F.col(\"annual_income\"))\n",
    "    .withColumn(\"credit_to_income\", F.col(\"total_credit_balance\") / F.col(\"annual_income\"))\n",
    "    .withColumn(\"installment_ratio\", F.col(\"payment_to_income\") / (F.col(\"debt_to_income\") + F.lit(1e-6)))\n",
    ")\n",
    "\n",
    "def map_col(df, colname, mapping_dict, default_val=0):\n",
    "    mapping_expr = F.create_map(\n",
    "        [F.lit(i) for kv in [[k, v] for k, v in mapping_dict.items()] for i in kv]\n",
    "    )\n",
    "    return df.withColumn(f\"{colname}_idx\", F.coalesce(mapping_expr[F.col(colname)], F.lit(default_val)))\n",
    "\n",
    "df = map_col(df, \"gender\", {\"Male\": 0, \"Female\": 1, \"Unknown\": 2})\n",
    "df = map_col(df, \"marital_status\", {\"Single\": 0, \"Married\": 1, \"Divorced\": 2, \"Widowed\": 3, \"Unknown\": 4})\n",
    "df = map_col(df, \"employment_type\", {\"Salaried\": 0, \"Self-Employed\": 1, \"Contract\": 2, \"Unknown\": 3})\n",
    "df = map_col(df, \"occupation_risk\", {\"Low\": 0, \"Medium\": 1, \"High\": 2, \"Unknown\": 3})\n",
    "df = map_col(df, \"purpose\", {\"Home\": 0, \"Car\": 1, \"Education\": 2, \"Business\": 3, \"Personal\": 4, \"Unknown\": 5})\n",
    "df = map_col(df, \"region_risk_tier\", {\"Low\": 0, \"Medium\": 1, \"High\": 2, \"Unknown\": 3})\n",
    "\n",
    "numeric_features = [\n",
    "    \"age\", \"dependents\", \"employment_length\", \"annual_income\", \"credit_score\",\n",
    "    \"num_open_accounts\", \"num_delinquencies\", \"avg_utilization_ratio\",\n",
    "    \"num_credit_inquiries\", \"loan_amount\", \"loan_term_months\", \"interest_rate\",\n",
    "    \"existing_loans_count\", \"debt_to_income\", \"payment_to_income\",\n",
    "    \"credit_limit_utilization\", \"total_credit_balance\", \"recent_missed_payments\",\n",
    "    \"time_since_last_default\", \"months_with_bank\",\n",
    "    \"loan_to_income\", \"credit_to_income\", \"installment_ratio\"\n",
    "]\n",
    "\n",
    "assembler_inputs = numeric_features + [\n",
    "    \"gender_idx\", \"marital_status_idx\", \"employment_type_idx\",\n",
    "    \"occupation_risk_idx\", \"purpose_idx\", \"region_risk_tier_idx\"\n",
    "]\n",
    "\n",
    "assembler = VectorAssembler(inputCols=assembler_inputs, outputCol=\"features\")\n",
    "features_df = assembler.transform(df)\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 4. Load champion model from MLflow UC registry\n",
    "# --------------------------------------------------\n",
    "model_name = \"banking.default.banking_credit_default_model\"\n",
    "model_uri = f\"models:/{model_name}@champion\"\n",
    "\n",
    "# Use the Spark flavor directly\n",
    "model = mlflow.spark.load_model(model_uri)\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 5. Generate predictions using Spark model\n",
    "# --------------------------------------------------\n",
    "predictions = model.transform(features_df)\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 6. Save results to inference table\n",
    "# --------------------------------------------------\n",
    "predictions.select(\n",
    "    \"prediction\",\n",
    "    \"age\", \"annual_income\", \"credit_score\", \"loan_amount\"\n",
    ").write.mode(\"overwrite\").saveAsTable(\"banking.default.inference_predictions\")\n",
    "\n",
    "print(\"✅ Step 5 complete – predictions written to banking.default.inference_predictions\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "07b4349b-bef8-4d6d-9f68-ade85dc5fa9b",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": null,
       "filterBlob": "{\"version\":1,\"filterGroups\":[{\"enabled\":true,\"filterGroupId\":\"fg_187a2ff\",\"op\":\"OR\",\"filters\":[{\"filterId\":\"f_8580c349\",\"enabled\":true,\"columnId\":\"prediction\",\"dataType\":\"float\",\"filterType\":\"oneof\"}],\"local\":false,\"updatedAt\":1762307137233}],\"syncTimestamp\":1762307137234}",
       "queryPlanFiltersBlob": "[]",
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "select * from banking.default.inference_predictions"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 4544651312606979,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Deploy",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
